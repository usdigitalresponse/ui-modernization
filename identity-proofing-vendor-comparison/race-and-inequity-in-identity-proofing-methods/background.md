# Background

In UI systems, there is a balance between finding fraud and getting benefits out in a timely manner. Right now, a lot of fraud is slipping through and benefits are severely delayed. As we work to shift this balance, we need to ensure that we reduce -- not broaden -- racial inequities in UI.

[During the Great Recession, young white men received UI benefits almost twice as often \(13.6%\) as young black men \(7.1%\)](https://www.urban.org/sites/default/files/publication/23311/412747-The-Labor-Market-Performance-of-Young-Black-Men-in-the-Great-Recession.PDF). While there are many factors at play, one piece that canâ€™t be ignored is the fact that [POC are more likely to be flagged for identity fraud](https://www.newamerica.org/pit/reports/unpacking-inequities-unemployment-insurance/a-focus-on-fraud-over-accessibility-the-punitive-design-of-ui/) \(though there is no evidence they are more likely to commit identity fraud\). 

Now is the right time to be looking at this issue, as the Continued Assistance Act of December 2020 created a new requirement for States to have digitized identity verification processes for Pandemic Unemployment Assistance. Many States had already begun doing, or actually completed this, by the time the legislation passed; however, even those States should look at their identity fraud detection processes \(including the contracts they have with vendors\) and surrounding user experience.

At the same time, States should also make sure that being flagged for potential identity theft does not on its own kick off other processes like trying to find benefits fraud so that the racially disparate outcomes are not compounded. 

